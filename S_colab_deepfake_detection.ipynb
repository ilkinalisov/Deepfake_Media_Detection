{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1L7KSGd6e1a"
      },
      "source": [
        "# Deepfake Detection with FaceForensics++ Dataset\n",
        "\n",
        "This notebook:\n",
        "1. Downloads the FaceForensics++ extracted frames dataset from Kaggle\n",
        "2. Processes frames and extracts features using MobileNetV2\n",
        "3. Trains multiple classifiers (Logistic Regression, SVM, MLP)\n",
        "4. Evaluates model performance\n",
        "\n",
        "**Dataset**: FaceForensics++ extracted frames (~192,000 frames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZEfKiUY6e1b",
        "outputId": "6951dd2b-9e3a-4c54-ca97-01ee16f9a116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install kagglehub opencv-python tqdm scikit-learn joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aK-t5bLv6e1c"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from pathlib import Path\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tqdm import tqdm\n",
        "import kagglehub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDs_JUZb6e1c"
      },
      "source": [
        "## Step 1: Download Dataset from Kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKXvPt5n6e1c",
        "outputId": "bf38c109-d02d-4b54-e2da-4e87503da43b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/adham7elmy/faceforencispp-extracted-frames?dataset_version_number=4...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13.4G/13.4G [10:27<00:00, 22.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/adham7elmy/faceforencispp-extracted-frames/versions/4\n",
            "\n",
            "Dataset structure:\n",
            "  real: DIR\n",
            "  fake: DIR\n"
          ]
        }
      ],
      "source": [
        "# Download latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"adham7elmy/faceforencispp-extracted-frames\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "print(\"\\nDataset structure:\")\n",
        "import os\n",
        "for item in os.listdir(path):\n",
        "    item_path = os.path.join(path, item)\n",
        "    size = os.path.getsize(item_path) if os.path.isfile(item_path) else \"DIR\"\n",
        "    print(f\"  {item}: {size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggPjANFe6e1c"
      },
      "source": [
        "## Step 2: Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf73GpfA6e1c",
        "outputId": "d6d05453-ced9-44ae-9118-dfc9fef646c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base dataset path: /root/.cache/kagglehub/datasets/adham7elmy/faceforencispp-extracted-frames/versions/4\n",
            "Actual data directory: /root/.cache/kagglehub/datasets/adham7elmy/faceforencispp-extracted-frames/versions/4\n",
            "\n",
            "Checking for 'real' and 'fake' directories:\n",
            "  real/ exists: True\n",
            "  fake/ exists: True\n",
            "  real/ contains 999 items\n",
            "    First item: 165 (DIR)\n",
            "  fake/ contains 5 items\n",
            "    First item: Deepfakes (DIR)\n",
            "\n",
            "Using dataset directory: /root/.cache/kagglehub/datasets/adham7elmy/faceforencispp-extracted-frames/versions/4\n",
            "Output directory: /content/features\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "random.seed(42)\n",
        "BATCH_SIZE = 32  # For feature extraction\n",
        "MAX_FRAMES_PER_VIDEO = 30  # Limit frames per video for memory efficiency\n",
        "\n",
        "# Dataset path (from kagglehub download)\n",
        "kaggle_dataset_dir = Path(path)\n",
        "\n",
        "# Find the actual data directory (might be nested)\n",
        "def find_data_directory(base_path):\n",
        "    \"\"\"Find the directory containing 'real' and 'fake' folders\"\"\"\n",
        "    # Check if real/fake are directly in base_path\n",
        "    if (base_path / \"real\").exists() and (base_path / \"fake\").exists():\n",
        "        return base_path\n",
        "\n",
        "    # Search one level deep\n",
        "    for item in base_path.iterdir():\n",
        "        if item.is_dir():\n",
        "            if (item / \"real\").exists() and (item / \"fake\").exists():\n",
        "                return item\n",
        "            # Search two levels deep\n",
        "            for subitem in item.iterdir():\n",
        "                if subitem.is_dir():\n",
        "                    if (subitem / \"real\").exists() and (subitem / \"fake\").exists():\n",
        "                        return subitem\n",
        "\n",
        "    return base_path  # Return original if not found\n",
        "\n",
        "actual_data_dir = find_data_directory(kaggle_dataset_dir)\n",
        "print(f\"Base dataset path: {kaggle_dataset_dir}\")\n",
        "print(f\"Actual data directory: {actual_data_dir}\")\n",
        "\n",
        "# Check what's in the directory\n",
        "print(\"\\nChecking for 'real' and 'fake' directories:\")\n",
        "real_path = actual_data_dir / \"real\"\n",
        "fake_path = actual_data_dir / \"fake\"\n",
        "print(f\"  real/ exists: {real_path.exists()}\")\n",
        "print(f\"  fake/ exists: {fake_path.exists()}\")\n",
        "\n",
        "if real_path.exists():\n",
        "    real_items = list(real_path.iterdir())\n",
        "    print(f\"  real/ contains {len(real_items)} items\")\n",
        "    if real_items:\n",
        "        print(f\"    First item: {real_items[0].name} ({'DIR' if real_items[0].is_dir() else 'FILE'})\")\n",
        "\n",
        "if fake_path.exists():\n",
        "    fake_items = list(fake_path.iterdir())\n",
        "    print(f\"  fake/ contains {len(fake_items)} items\")\n",
        "    if fake_items:\n",
        "        print(f\"    First item: {fake_items[0].name} ({'DIR' if fake_items[0].is_dir() else 'FILE'})\")\n",
        "\n",
        "# Use the found directory\n",
        "kaggle_dataset_dir = actual_data_dir\n",
        "\n",
        "# Output directory for features (in Colab's temporary storage)\n",
        "output_dir = Path(\"/content/features\")\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\nUsing dataset directory: {kaggle_dataset_dir}\")\n",
        "print(f\"Output directory: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgoGvPpo6e1c"
      },
      "source": [
        "## Step 3: Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hkJQhZPI6e1d"
      },
      "outputs": [],
      "source": [
        "def preprocess_frame(frame_path):\n",
        "    \"\"\"Load and preprocess a single frame.\"\"\"\n",
        "    frame = cv2.imread(str(frame_path))\n",
        "    if frame is None:\n",
        "        return None\n",
        "    frame = cv2.resize(frame, (224, 224))\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR\n",
        "    frame = frame.astype(\"float32\") / 255.0\n",
        "    return frame\n",
        "\n",
        "def group_frames_by_video(frame_paths):\n",
        "    \"\"\"\n",
        "    Group frames by video based on filename patterns.\n",
        "    Assumes filenames like: 000_003_0001.png, 000_003_0002.png -> video 000_003\n",
        "    Or: 000_0001.png, 000_0002.png -> video 000\n",
        "    \"\"\"\n",
        "    video_groups = defaultdict(list)\n",
        "\n",
        "    for frame_path in frame_paths:\n",
        "        # Extract video identifier from filename\n",
        "        filename = frame_path.stem\n",
        "        parts = filename.split('_')\n",
        "\n",
        "        # Determine video ID (everything except the last part which is frame number)\n",
        "        if len(parts) >= 2:\n",
        "            # Check if last part is numeric (frame number)\n",
        "            if parts[-1].isdigit():\n",
        "                video_id = '_'.join(parts[:-1])\n",
        "            else:\n",
        "                video_id = filename  # Use full name if pattern unclear\n",
        "        else:\n",
        "            video_id = filename\n",
        "\n",
        "        video_groups[video_id].append(frame_path)\n",
        "\n",
        "    return video_groups\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q__xjRbQ6e1d"
      },
      "source": [
        "## Step 4: Build Feature Extractor (MobileNetV2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2mwGXwo6e1d",
        "outputId": "7c654914-6a62-4e9a-dea2-72b7a220aa28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building MobileNetV2 feature extractor...\n",
            "Feature dimension: 1280\n"
          ]
        }
      ],
      "source": [
        "# Build MobileNetV2 feature extractor\n",
        "print(\"Building MobileNetV2 feature extractor...\")\n",
        "base_model = MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "feature_extractor = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "print(f\"Feature dimension: {feature_extractor.output_shape[1]}\")\n",
        "\n",
        "def extract_features_batch(frames):\n",
        "    \"\"\"Extract features from a batch of frames.\"\"\"\n",
        "    frames_array = np.array(frames, dtype=\"float32\")\n",
        "    frame_features = feature_extractor.predict(frames_array, verbose=0, batch_size=BATCH_SIZE)\n",
        "    return frame_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6uhMy9v6e1d"
      },
      "source": [
        "## Step 5: Process Dataset and Extract Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7ghtSwR6e1d",
        "outputId": "9cd2921c-1530-4b91-d3ef-35071c0037be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Processing REAL frames...\n",
            "============================================================\n",
            "Searching in: /root/.cache/kagglehub/datasets/adham7elmy/faceforencispp-extracted-frames/versions/4/real\n",
            "Total real frames found: 31949\n",
            "Grouped into 1089 videos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing real videos: 100%|██████████| 1089/1089 [15:56<00:00,  1.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Processed 1089 real videos\n",
            "\n",
            "============================================================\n",
            "Processing FAKE frames...\n",
            "============================================================\n",
            "Searching in: /root/.cache/kagglehub/datasets/adham7elmy/faceforencispp-extracted-frames/versions/4/fake\n",
            "  Found 31843 frames in Deepfakes/\n",
            "  Found 31954 frames in FaceSwap/\n",
            "  Found 31924 frames in FaceShifter/\n",
            "  Found 31931 frames in NeuralTextures/\n",
            "  Found 31949 frames in Face2Face/\n",
            "  Found 159601 frames directly in fake/\n",
            "Total fake frames found: 319202\n",
            "Grouped into 1089 videos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing fake videos: 100%|██████████| 1089/1089 [22:39<00:00,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Processed 1089 fake videos\n",
            "\n",
            "============================================================\n",
            "Total videos processed: 2178\n",
            "Feature shape: (1280,)\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Process the dataset\n",
        "video_features_dict = {}\n",
        "\n",
        "def find_frame_files(directory, extensions=['.png', '.jpg', '.jpeg']):\n",
        "    \"\"\"Recursively find all image files in directory\"\"\"\n",
        "    frame_files = []\n",
        "    for ext in extensions:\n",
        "        frame_files.extend(list(directory.rglob(f\"*{ext}\")))\n",
        "        frame_files.extend(list(directory.rglob(f\"*{ext.upper()}\")))\n",
        "    return frame_files\n",
        "\n",
        "for class_name in [\"real\", \"fake\"]:\n",
        "    class_path = kaggle_dataset_dir / class_name\n",
        "\n",
        "    if not class_path.exists():\n",
        "        print(f\"Warning: {class_path} does not exist. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing {class_name.upper()} frames...\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Searching in: {class_path}\")\n",
        "\n",
        "    # Get all frame files (search recursively for PNG, JPG, JPEG)\n",
        "    if class_name == \"fake\":\n",
        "        # Fake directory has subdirectories (Deepfakes, Face2Face, etc.)\n",
        "        frame_files = []\n",
        "        subdirs_found = []\n",
        "        for subdir in class_path.iterdir():\n",
        "            if subdir.is_dir():\n",
        "                subdir_frames = find_frame_files(subdir)\n",
        "                frame_files.extend(subdir_frames)\n",
        "                subdirs_found.append(subdir.name)\n",
        "                print(f\"  Found {len(subdir_frames)} frames in {subdir.name}/\")\n",
        "\n",
        "        # Also check if there are frames directly in fake/ directory\n",
        "        direct_frames = find_frame_files(class_path)\n",
        "        if direct_frames:\n",
        "            print(f\"  Found {len(direct_frames)} frames directly in fake/\")\n",
        "            frame_files.extend(direct_frames)\n",
        "    else:\n",
        "        # Real directory - search recursively\n",
        "        frame_files = find_frame_files(class_path)\n",
        "\n",
        "    print(f\"Total {class_name} frames found: {len(frame_files)}\")\n",
        "\n",
        "    if len(frame_files) == 0:\n",
        "        print(f\"⚠️  WARNING: No frames found in {class_path}\")\n",
        "        print(f\"   Trying to list directory contents...\")\n",
        "        try:\n",
        "            items = list(class_path.iterdir())\n",
        "            print(f\"   Directory contains {len(items)} items\")\n",
        "            for item in items[:5]:\n",
        "                print(f\"     - {item.name} ({'DIR' if item.is_dir() else 'FILE'})\")\n",
        "        except Exception as e:\n",
        "            print(f\"   Error listing directory: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Group by video and create video-level features\n",
        "    video_groups = group_frames_by_video(frame_files)\n",
        "    print(f\"Grouped into {len(video_groups)} videos\")\n",
        "\n",
        "    if len(video_groups) == 0:\n",
        "        print(f\"⚠️  WARNING: Could not group frames into videos\")\n",
        "        continue\n",
        "\n",
        "    # Process each video\n",
        "    for video_id, frame_paths in tqdm(video_groups.items(), desc=f\"Processing {class_name} videos\"):\n",
        "        # Limit frames per video\n",
        "        if len(frame_paths) > MAX_FRAMES_PER_VIDEO:\n",
        "            frame_paths = random.sample(frame_paths, MAX_FRAMES_PER_VIDEO)\n",
        "\n",
        "        # Load and preprocess frames\n",
        "        frames = []\n",
        "        for frame_path in frame_paths:\n",
        "            frame = preprocess_frame(frame_path)\n",
        "            if frame is not None:\n",
        "                frames.append(frame)\n",
        "\n",
        "        if not frames:\n",
        "            continue\n",
        "\n",
        "        # Extract features\n",
        "        frame_features = extract_features_batch(frames)\n",
        "\n",
        "        # Average features across frames to get video-level feature\n",
        "        video_feature = np.mean(frame_features, axis=0)\n",
        "\n",
        "        # Store with unique video identifier\n",
        "        unique_video_id = f\"{class_name}_{video_id}\"\n",
        "        video_features_dict[unique_video_id] = video_feature\n",
        "\n",
        "    print(f\"✓ Processed {len(video_groups)} {class_name} videos\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Total videos processed: {len(video_features_dict)}\")\n",
        "\n",
        "if len(video_features_dict) > 0:\n",
        "    print(f\"Feature shape: {next(iter(video_features_dict.values())).shape}\")\n",
        "else:\n",
        "    print(\"⚠️  ERROR: No videos were processed!\")\n",
        "    print(\"Please check:\")\n",
        "    print(\"  1. The dataset was downloaded correctly\")\n",
        "    print(\"  2. The directory structure matches expected format\")\n",
        "    print(\"  3. Image files are in PNG, JPG, or JPEG format\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tbGUJxd6e1d"
      },
      "source": [
        "## Step 6: Prepare Feature Matrix and Labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjX6OaoH6e1d",
        "outputId": "68d3b761-7337-4d18-8034-21a3424604e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature matrix shape: (2178, 1280)\n",
            "Labels shape: (2178,)\n",
            "\n",
            "Class distribution:\n",
            "  Real (0): 1089 videos\n",
            "  Fake (1): 1089 videos\n",
            "  Total: 2178 videos\n",
            "\n",
            "✓ Features saved to /content/features\n"
          ]
        }
      ],
      "source": [
        "# Prepare feature matrix and labels\n",
        "if len(video_features_dict) == 0:\n",
        "    print(\"⚠️  ERROR: No features extracted. Cannot proceed with training.\")\n",
        "    print(\"Please check the dataset structure and try again.\")\n",
        "    raise ValueError(\"No videos were processed. Check dataset structure.\")\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for video_id, feature in video_features_dict.items():\n",
        "    X.append(feature)\n",
        "    # Extract label from video_id (format: \"real_video_id\" or \"fake_video_id\")\n",
        "    label = 0 if video_id.startswith(\"real_\") else 1\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(f\"  Real (0): {np.sum(y == 0)} videos\")\n",
        "print(f\"  Fake (1): {np.sum(y == 1)} videos\")\n",
        "print(f\"  Total: {len(y)} videos\")\n",
        "\n",
        "# Save features for later use\n",
        "np.save(output_dir / \"X_video_features.npy\", X)\n",
        "np.save(output_dir / \"y_video_label.npy\", y)\n",
        "print(f\"\\n✓ Features saved to {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXmRYD-L6e1d"
      },
      "source": [
        "## Step 7: Train-Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5xFFiD66e1d",
        "outputId": "8991f4f7-06e4-42e2-89c5-9087133216db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set: 1742 samples\n",
            "Test set: 436 samples\n",
            "\n",
            "Train class distribution:\n",
            "  Real: 871, Fake: 871\n",
            "Test class distribution:\n",
            "  Real: 218, Fake: 218\n"
          ]
        }
      ],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"\\nTrain class distribution:\")\n",
        "print(f\"  Real: {np.sum(y_train == 0)}, Fake: {np.sum(y_train == 1)}\")\n",
        "print(f\"Test class distribution:\")\n",
        "print(f\"  Real: {np.sum(y_test == 0)}, Fake: {np.sum(y_test == 1)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPKc-bWK6e1e"
      },
      "source": [
        "## Step 8: Feature Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2jRPCSq6e1e",
        "outputId": "9f802abc-c754-4a03-83a7-3f843373ebca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Features standardized\n"
          ]
        }
      ],
      "source": [
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"✓ Features standardized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-V5EF_B6e1e"
      },
      "source": [
        "## Step 9: Train Models\n",
        "\n",
        "### 9.1 Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6xVd37a6e1e",
        "outputId": "27e50316-873f-4c51-f782-e213a8e32cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Logistic Regression...\n",
            "\n",
            "============================================================\n",
            "LOGISTIC REGRESSION RESULTS\n",
            "============================================================\n",
            "Accuracy: 0.8899\n",
            "F1 Score: 0.8904\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.89      0.89      0.89       218\n",
            "        Fake       0.89      0.89      0.89       218\n",
            "\n",
            "    accuracy                           0.89       436\n",
            "   macro avg       0.89      0.89      0.89       436\n",
            "weighted avg       0.89      0.89      0.89       436\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[193  25]\n",
            " [ 23 195]]\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "print(\"Training Logistic Regression...\")\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LOGISTIC REGRESSION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred_lr):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=['Real', 'Fake']))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3aZ8gx6e1e"
      },
      "source": [
        "### 9.2 Support Vector Machine (SVM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LEcmBzD6e1e",
        "outputId": "573481d7-5c5f-4798-abed-e093e34af12b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training SVM (this may take a few minutes)...\n",
            "\n",
            "============================================================\n",
            "SVM RESULTS\n",
            "============================================================\n",
            "Accuracy: 0.8945\n",
            "F1 Score: 0.8905\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.87      0.93      0.90       218\n",
            "        Fake       0.93      0.86      0.89       218\n",
            "\n",
            "    accuracy                           0.89       436\n",
            "   macro avg       0.90      0.89      0.89       436\n",
            "weighted avg       0.90      0.89      0.89       436\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[203  15]\n",
            " [ 31 187]]\n"
          ]
        }
      ],
      "source": [
        "# Support Vector Machine\n",
        "print(\"Training SVM (this may take a few minutes)...\")\n",
        "svm = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SVM RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred_svm):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=['Real', 'Fake']))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdRNT4Gl6e1e"
      },
      "source": [
        "### 9.3 Multi-Layer Perceptron (MLP)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMvzCMW06e1e",
        "outputId": "347d5f70-53fb-4782-a705-1f8aa43d4b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MLP...\n",
            "\n",
            "============================================================\n",
            "MLP RESULTS\n",
            "============================================================\n",
            "Accuracy: 0.9060\n",
            "F1 Score: 0.9066\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.91      0.90      0.91       218\n",
            "        Fake       0.90      0.91      0.91       218\n",
            "\n",
            "    accuracy                           0.91       436\n",
            "   macro avg       0.91      0.91      0.91       436\n",
            "weighted avg       0.91      0.91      0.91       436\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[196  22]\n",
            " [ 19 199]]\n"
          ]
        }
      ],
      "source": [
        "# Multi-Layer Perceptron\n",
        "print(\"Training MLP...\")\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(128, 64),\n",
        "    max_iter=300,\n",
        "    random_state=42,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1\n",
        ")\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_mlp = mlp.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MLP RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_mlp):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred_mlp):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_mlp, target_names=['Real', 'Fake']))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_mlp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3aoge3D6e1e"
      },
      "source": [
        "## Step 10: Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "a9qZwelC6e1e",
        "outputId": "bd1630ea-727d-4878-efe3-5d90f31385b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "MODEL COMPARISON\n",
            "============================================================\n",
            "              Model  Accuracy  F1 Score\n",
            "Logistic Regression  0.889908  0.890411\n",
            "                SVM  0.894495  0.890476\n",
            "                MLP  0.905963  0.906606\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compare all models\n",
        "results = {\n",
        "    'Model': ['Logistic Regression', 'SVM', 'MLP'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred_lr),\n",
        "        accuracy_score(y_test, y_pred_svm),\n",
        "        accuracy_score(y_test, y_pred_mlp)\n",
        "    ],\n",
        "    'F1 Score': [\n",
        "        f1_score(y_test, y_pred_lr),\n",
        "        f1_score(y_test, y_pred_svm),\n",
        "        f1_score(y_test, y_pred_mlp)\n",
        "    ]\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Visualize comparison\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "models = results['Model']\n",
        "accuracies = results['Accuracy']\n",
        "f1_scores = results['F1 Score']\n",
        "\n",
        "ax1.bar(models, accuracies, color=['#3498db', '#2ecc71', '#e74c3c'])\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Model Accuracy Comparison')\n",
        "ax1.set_ylim([0, 1])\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "ax2.bar(models, f1_scores, color=['#3498db', '#2ecc71', '#e74c3c'])\n",
        "ax2.set_ylabel('F1 Score')\n",
        "ax2.set_title('Model F1 Score Comparison')\n",
        "ax2.set_ylim([0, 1])\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9jU6Nxq6e1e"
      },
      "source": [
        "## Step 11: Save Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9WUbfnX6e1e",
        "outputId": "0a3f0369-900e-4a3b-e674-7d829d0e0f28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Best model (SVM) saved to /content/models\n",
            "✓ Scaler saved to /content/models\n",
            "\n",
            "All models saved:\n",
            "  - video_svm.pkl (SVM)\n",
            "  - video_lr.pkl (Logistic Regression)\n",
            "  - video_mlp.pkl (MLP)\n",
            "  - scaler.pkl (StandardScaler)\n"
          ]
        }
      ],
      "source": [
        "# Save the best model (SVM typically performs best)\n",
        "models_dir = Path(\"/content/models\")\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save SVM model and scaler\n",
        "joblib.dump(svm, models_dir / \"video_svm.pkl\")\n",
        "joblib.dump(scaler, models_dir / \"scaler.pkl\")\n",
        "\n",
        "print(f\"✓ Best model (SVM) saved to {models_dir}\")\n",
        "print(f\"✓ Scaler saved to {models_dir}\")\n",
        "\n",
        "# Also save other models if needed\n",
        "joblib.dump(lr, models_dir / \"video_lr.pkl\")\n",
        "joblib.dump(mlp, models_dir / \"video_mlp.pkl\")\n",
        "\n",
        "print(f\"\\nAll models saved:\")\n",
        "print(f\"  - video_svm.pkl (SVM)\")\n",
        "print(f\"  - video_lr.pkl (Logistic Regression)\")\n",
        "print(f\"  - video_mlp.pkl (MLP)\")\n",
        "print(f\"  - scaler.pkl (StandardScaler)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKtp1IIE6e1e"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook has:\n",
        "1. ✅ Downloaded the FaceForensics++ extracted frames dataset\n",
        "2. ✅ Processed ~192,000 frames and extracted features using MobileNetV2\n",
        "3. ✅ Trained three classifiers (Logistic Regression, SVM, MLP)\n",
        "4. ✅ Evaluated and compared model performance\n",
        "5. ✅ Saved the best model for future use\n",
        "\n",
        "**Next Steps:**\n",
        "- You can download the saved models from Colab's file browser\n",
        "- Use the models for inference on new videos\n",
        "- Experiment with different architectures or hyperparameters\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
