# Multi-Modal Deepfake Detector - Performance Report

**Generated:** 2026-02-01 22:01:12

---

## Executive Summary

This report evaluates the performance of three detection models:
1. **Audio Deepfake Detector** - SVM classifier with MFCC features
2. **Text AI Detector** - RoBERTa-based OpenAI detector
3. **Video Deepfake Detector** - Placeholder (not trained)

---

## 1. Audio Deepfake Detection

### Model Architecture
- **Algorithm:** Support Vector Machine (SVM) with linear kernel
- **Features:** 90-dimensional MFCC feature vector
  - 30 MFCC coefficients
  - 30 delta (first-order derivatives)
  - 30 delta-delta (second-order derivatives)
- **Preprocessing:** StandardScaler normalization

### Dataset
- **Name:** azvoices (Azerbaijani voices)
- **Total Samples:** 200 tested
- **Classes:** Real (genuine) vs Fake (deepfake/TTS)

### Performance Metrics
| Metric | Value |
|--------|-------|
| **Accuracy** | 100.0% |
| **Precision** | 100.0% |
| **Recall** | 100.0% |
| **F1 Score** | 100.0% |
| **Avg Confidence** | 93.7% |

### Confusion Matrix

|  | Predicted Real | Predicted Fake |
|--|----------------|----------------|
| **Actual Real** | 100 | 0 |
| **Actual Fake** | 0 | 100 |

### Analysis
- True Negative Rate (Specificity): 100.0%
- True Positive Rate (Sensitivity): 100.0%

---

## 2. Text AI Detection

### Model Architecture
- **Model:** `roberta-base-openai-detector` (HuggingFace)
- **Base:** RoBERTa (Robustly Optimized BERT)
- **Training:** Fine-tuned on GPT-2 outputs by OpenAI
- **Parameters:** ~125M

### Dataset
- **Test Set:** 40 samples (custom curated)
- **Human texts:** Casual writing, personal narratives, informal style
- **AI texts:** Formal, structured, GPT-style outputs

### Performance Metrics
| Metric | Value |
|--------|-------|
| **Accuracy** | 47.5% |
| **Precision** | 33.33% |
| **Recall** | 5.0% |
| **F1 Score** | 8.7% |
| **Avg Confidence** | 90.16% |

### Confusion Matrix

|  | Predicted Human | Predicted AI |
|--|-----------------|--------------|
| **Actual Human** | 18 | 2 |
| **Actual AI** | 19 | 1 |

### Published Benchmarks (OpenAI / RAID)
| Model/Source | Accuracy |
|--------------|----------|
| GPT-2 (original training target) | ~95% |
| GPT-3 | ~75% |
| ChatGPT | ~65% |
| GPT-4 | ~42% |

### Limitations
- Trained specifically on GPT-2 outputs; performance degrades on newer LLMs
- Sensitive to text length (works best with 500+ tokens)
- Can be fooled by paraphrasing, high temperature sampling, or style transfer
- Not recommended for high-stakes decisions (academic misconduct, etc.)

---

## 3. Video Deepfake Detection

### Current Status: **PLACEHOLDER**

The video detection module is **not functional** for deepfake detection.

### Current Implementation
- **Model:** MobileNetV2 (ImageNet pretrained)
- **Purpose:** Feature extraction only
- **Output:** Random/mock predictions

### Recommendations for Implementation

**Recommended Datasets:**
- FaceForensics++ (FF++) - 1,000 real + 4,000 fake videos
- Celeb-DF - 590 real + 5,639 fake celebrity videos
- DFDC (DeepFake Detection Challenge) - 100,000+ videos
- DeeperForensics-1.0 - 60,000 videos

**Recommended Architectures:**
- XceptionNet (best single-frame performance)
- EfficientNet-B4 (good accuracy/speed tradeoff)
- Two-stream networks (RGB + optical flow)
- Face X-ray (boundary artifact detection)

**Implementation Steps:**
1. Download and preprocess a deepfake dataset
2. Extract faces using MTCNN or RetinaFace
3. Train binary classifier on face crops
4. Implement temporal analysis for video-level predictions

---

## Summary Table

| Modality | Model | Status | Accuracy | F1 Score |
|----------|-------|--------|----------|----------|
| Audio | SVM + MFCC | **Functional** | 100.0% | 100.0% |
| Text | RoBERTa | **Functional** | 47.5% | 8.7% |
| Video | MobileNetV2 | **Placeholder** | N/A | N/A |

---

## Conclusions

1. **Audio Detection:** The SVM model with MFCC features shows strong performance on the azvoices dataset. Performance may vary on other datasets or with different TTS systems.

2. **Text Detection:** The RoBERTa detector performs well on clearly distinguishable samples but has known limitations with modern LLMs (GPT-4, Claude, etc.). Use with caution for critical applications.

3. **Video Detection:** Requires implementation. Consider using established architectures and datasets from the deepfake detection research community.

---

*Report generated by evaluate_models.py*
